{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9w0623hDP7bKWsqajYwYZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohithsarikela/hackathonTask1/blob/main/Copy_of_task1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrTKwUA0X3qS",
        "outputId": "88730961-4c4a-4099-9a64-a85467f8abb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp1NVkQDYi3S",
        "outputId": "714c6184-de3a-4272-9f8d-2b7d9d68480a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.9.0.post1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from PyPDF2 import PdfReader\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "from transformers import pipeline\n",
        "\n",
        "def download_pdf_from_url(url, save_path):\n",
        "    \"\"\"Download a PDF file from a URL.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        with open(save_path, 'wb') as file:\n",
        "            file.write(response.content)\n",
        "        print(f\"PDF downloaded successfully to '{save_path}'\")\n",
        "        return save_path\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error downloading PDF: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extract text from a PDF file.\"\"\"\n",
        "    extracted_text = \"\"\n",
        "    try:\n",
        "        reader = PdfReader(pdf_path)\n",
        "        for page in reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                extracted_text += page_text + \"\\n\"\n",
        "        return extracted_text if extracted_text else \"No text found in PDF.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def chunk_text(text, chunk_size=500):\n",
        "    \"\"\"Split text into smaller chunks.\"\"\"\n",
        "    return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "\n",
        "def create_vector_database(chunks, embedding_model_name='all-MiniLM-L6-v2'):\n",
        "    \"\"\"Embed text chunks and store them in a FAISS vector database.\"\"\"\n",
        "    try:\n",
        "        model = SentenceTransformer(embedding_model_name)\n",
        "        embeddings = model.encode(chunks)\n",
        "        vector_dimension = embeddings.shape[1]\n",
        "        index = faiss.IndexFlatL2(vector_dimension)\n",
        "        index.add(embeddings)\n",
        "        return index, model\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating vector database: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def query_vector_database(query, chunks, index, model, top_k=5):\n",
        "    \"\"\"Retrieve relevant chunks for a given query.\"\"\"\n",
        "    query_embedding = model.encode([query])\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "    return [(chunks[i], distances[0][j]) for j, i in enumerate(indices[0])]\n",
        "\n",
        "def generate_response(retrieved_chunks, query, llm_model_name='t5-small', device=-1):\n",
        "    \"\"\"Generate an answer using a summarization pipeline.\"\"\"\n",
        "    try:\n",
        "        summarizer = pipeline(\"summarization\", model=llm_model_name, tokenizer=llm_model_name, device=device)\n",
        "        context = \" \".join([chunk for chunk, _ in retrieved_chunks])\n",
        "        prompt = f\"Context: {context}\\n\\nQuestion: {query}\\nAnswer concisely:\"\n",
        "        response = summarizer(prompt, max_length=150, min_length=50, do_sample=False)\n",
        "        return f\"**Question:** {query}\\n**Answer:** {response[0]['summary_text']}\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating response: {e}\")\n",
        "        return \"Unable to generate a response.\"\n",
        "\n",
        "def extract_table_from_page(pdf_path, page_num):\n",
        "    \"\"\"Extract table-like data from a specific PDF page.\"\"\"\n",
        "    try:\n",
        "        reader = PdfReader(pdf_path)\n",
        "        if page_num < 0 or page_num >= len(reader.pages):\n",
        "            return f\"Invalid page number: {page_num + 1}\"\n",
        "        page_text = reader.pages[page_num].extract_text()\n",
        "        if not page_text:\n",
        "            return \"No table data found on this page.\"\n",
        "        lines = page_text.split(\"\\n\")\n",
        "        table_data = [line.split() for line in lines if line.strip()]\n",
        "        return table_data\n",
        "    except Exception as e:\n",
        "        return f\"Error extracting table data: {e}\"\n",
        "\n",
        "def main():\n",
        "    # PDF URL and file location\n",
        "    pdf_url = \"https://www.hunter.cuny.edu/dolciani/pdf_files/workshop-materials/mmc-presentations/tables-charts-and-graphs-with-examples-from.pdf\"\n",
        "    local_pdf_file = \"downloaded_file.pdf\"\n",
        "\n",
        "    # Step 1: Download PDF\n",
        "    print(\"Downloading PDF...\")\n",
        "    pdf_path = download_pdf_from_url(pdf_url, local_pdf_file)\n",
        "    if not pdf_path:\n",
        "        return\n",
        "\n",
        "    # Step 2: Extract and chunk text\n",
        "    print(\"Extracting text from PDF...\")\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "    if not text or text == \"No text found in PDF.\":\n",
        "        print(\"No content extracted from PDF.\")\n",
        "        return\n",
        "\n",
        "    print(\"Splitting text into chunks...\")\n",
        "    chunks = chunk_text(text)\n",
        "\n",
        "    # Step 3: Create vector database\n",
        "    print(\"Creating vector database...\")\n",
        "    index, model = create_vector_database(chunks)\n",
        "    if not index or not model:\n",
        "        print(\"Vector database could not be created.\")\n",
        "        return\n",
        "\n",
        "    # Interactive Menu\n",
        "    while True:\n",
        "        print(\"\\nMenu Options:\")\n",
        "        print(\"1. Ask a question\")\n",
        "        print(\"2. Perform a comparison query\")\n",
        "        print(\"3. Extract tabular data from a page\")\n",
        "        print(\"4. Exit\")\n",
        "\n",
        "        choice = input(\"Enter your choice (1/2/3/4): \").strip()\n",
        "\n",
        "        if choice == \"1\":\n",
        "            query = input(\"Enter your question: \").strip()\n",
        "            if not query:\n",
        "                print(\"Question cannot be empty. Try again.\")\n",
        "                continue\n",
        "            retrieved_chunks = query_vector_database(query, chunks, index, model)\n",
        "            response = generate_response(retrieved_chunks, query)\n",
        "            print(response)\n",
        "\n",
        "        elif choice == \"2\":\n",
        "            try:\n",
        "                n = int(input(\"How many queries for comparison? \").strip())\n",
        "                queries = [input(f\"Enter query {i + 1}: \").strip() for i in range(n)]\n",
        "                results = {}\n",
        "                for query in queries:\n",
        "                    retrieved_chunks = query_vector_database(query, chunks, index, model)\n",
        "                    results[query] = retrieved_chunks\n",
        "                for query, retrieved_chunks in results.items():\n",
        "                    response = generate_response(retrieved_chunks, query)\n",
        "                    print(response)\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Please enter a valid number for queries.\")\n",
        "\n",
        "        elif choice == \"3\":\n",
        "            try:\n",
        "                page_num = int(input(\"Enter page number (starting from 1): \").strip()) - 1\n",
        "                table_data = extract_table_from_page(pdf_path, page_num)\n",
        "                if isinstance(table_data, str):\n",
        "                    print(table_data)\n",
        "                else:\n",
        "                    print(\"\\nExtracted Table Data:\")\n",
        "                    for row in table_data:\n",
        "                        print(\" \".join(row))\n",
        "            except ValueError:\n",
        "                print(\"Invalid page number. Please enter a valid integer.\")\n",
        "\n",
        "        elif choice == \"4\":\n",
        "            print(\"Exiting program. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid choice. Please select 1, 2, 3, or 4.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlC1KdKNdqRJ",
        "outputId": "82a3b404-702b-44c5-9372-385c9491fb1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading PDF...\n",
            "PDF downloaded successfully to 'downloaded_file.pdf'\n",
            "Extracting text from PDF...\n",
            "Splitting text into chunks...\n",
            "Creating vector database...\n",
            "\n",
            "Menu Options:\n",
            "1. Ask a question\n",
            "2. Perform a comparison query\n",
            "3. Extract tabular data from a page\n",
            "4. Exit\n",
            "Enter your choice (1/2/3/4): 3\n",
            "Enter page number (starting from 1): 6\n",
            "\n",
            "Extracted Table Data:\n",
            "Table of Yearly U.S. GDP by\n",
            "Industry (in millions of dollars)\n",
            "Year 2010 2011 2012 2013 2014 2015\n",
            "All Industries 26093515 27535971 28663246 29601191 30895407 31397023\n",
            "Manufacturing 4992521 5581942 5841608 5953299 6047477 5829554\n",
            "Finance,\n",
            "Insurance, Real\n",
            "Estate, Rental,\n",
            "Leasing4522451 4618678 4797313 5031881 5339678 5597018\n",
            "Arts,\n",
            "Entertainment,\n",
            "Recreation,\n",
            "Accommodation,\n",
            "and Food Service964032 1015238 1076249 1120496 1189646 1283813\n",
            "Other 15614511 16320113 16948076 17495515 18318606 18686638Source: U.S. Bureau of Labor Statistics\n",
            "\n",
            "Menu Options:\n",
            "1. Ask a question\n",
            "2. Perform a comparison query\n",
            "3. Extract tabular data from a page\n",
            "4. Exit\n",
            "Enter your choice (1/2/3/4): 4\n",
            "Exiting program. Goodbye!\n"
          ]
        }
      ]
    }
  ]
}